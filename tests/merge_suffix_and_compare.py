#!/usr/bin/env python3
"""
–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ article + article_suffix –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–æ–º
"""
import json
from pathlib import Path
from typing import Dict, Any, List

def merge_suffix_files(output_dir: Path, reference_file: Path):
    """–ù–∞—Ö–æ–¥–∏—Ç —Ñ–∞–π–ª—ã —Å suffix, –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç article + suffix, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å —ç—Ç–∞–ª–æ–Ω–æ–º"""

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —ç—Ç–∞–ª–æ–Ω
    with open(reference_file, 'r', encoding='utf-8') as f:
        ref_data = json.load(f)

    ref_items = ref_data.get('table_data', {}).get('line_items', [])
    ref_art_key = next((k for k in ref_items[0].keys() if 'article' in k.lower()), None)

    if not ref_art_key:
        print("‚ùå –ö–ª—é—á –∞—Ä—Ç–∏–∫—É–ª–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —ç—Ç–∞–ª–æ–Ω–µ")
        return

    print("=" * 80)
    print("–û–ë–†–ê–ë–û–¢–ö–ê –§–ê–ô–õ–û–í –° SUFFIX")
    print("=" * 80)
    print(f"\nüìã –≠—Ç–∞–ª–æ–Ω: {len(ref_items)} —Å—Ç—Ä–æ–∫, –∫–ª—é—á: '{ref_art_key}'")
    print()

    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã —Å suffix
    all_files = list(output_dir.rglob("*dnipromash*.json"))

    files_with_suffix = []

    for f in sorted(all_files):
        try:
            with open(f, 'r', encoding='utf-8') as file:
                data = json.load(file)

            items = data.get('table_data', {}).get('line_items', [])
            if not items:
                continue

            first_row = items[0]
            cols = list(first_row.keys())

            # –ò—â–µ–º –∫–ª—é—á–∏ —Å suffix
            suffix_key = None
            article_key = None

            for k in cols:
                k_lower = k.lower()
                if 'suffix' in k_lower or 'modifier' in k_lower:
                    suffix_key = k
                if 'article' in k_lower and 'suffix' not in k_lower and 'modifier' not in k_lower:
                    article_key = k

            if suffix_key and article_key:
                files_with_suffix.append({
                    'file': f,
                    'article_key': article_key,
                    'suffix_key': suffix_key,
                    'data': data
                })

        except Exception as e:
            pass

    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(files_with_suffix)} —Ñ–∞–π–ª–æ–≤ —Å suffix\n")

    results = []

    for item in files_with_suffix:
        f = item['file']
        article_key = item['article_key']
        suffix_key = item['suffix_key']
        data = item['data']

        print(f"üìÑ {f.relative_to(output_dir)}")
        print(f"   article_key: {article_key}")
        print(f"   suffix_key: {suffix_key}")

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º article + suffix
        items = data.get('table_data', {}).get('line_items', [])
        merged_count = 0

        for row in items:
            article_val = str(row.get(article_key, '')).strip()
            suffix_val = str(row.get(suffix_key, '')).strip()

            if suffix_val and suffix_val != '':
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º
                merged_article = article_val + suffix_val
                row[article_key] = merged_article
                merged_count += 1
                # –£–¥–∞–ª—è–µ–º suffix
                del row[suffix_key]

        # –£–¥–∞–ª—è–µ–º suffix –∏–∑ column_mapping
        column_mapping = data.get('table_data', {}).get('column_mapping', {})
        if suffix_key in column_mapping:
            del column_mapping[suffix_key]

        print(f"   –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ —Å—Ç—Ä–æ–∫: {merged_count}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
        processed_file = f.parent / f"{f.stem}_merged.json"
        with open(processed_file, 'w', encoding='utf-8') as out_file:
            json.dump(data, out_file, ensure_ascii=False, indent=2)

        print(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {processed_file.name}")

        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å —ç—Ç–∞–ª–æ–Ω–æ–º
        min_len = min(len(items), len(ref_items))
        errors = []

        for i in range(min_len):
            result_art = str(items[i].get(article_key, '')).strip()
            ref_art = str(ref_items[i].get(ref_art_key, '')).strip()

            result_clean = result_art.replace(' ', '').replace('.', '').replace('-', '')
            ref_clean = ref_art.replace(' ', '').replace('.', '').replace('-', '')

            if result_clean != ref_clean:
                errors.append({
                    'row': i + 1,
                    'result': result_art,
                    'reference': ref_art
                })

        if not errors:
            print(f"   ‚úÖ –ò–î–ï–ê–õ–¨–ù–û! –í—Å–µ {min_len} –∞—Ä—Ç–∏–∫—É–ª–æ–≤ —Å–æ–≤–ø–∞–¥–∞—é—Ç!")
            status = "PERFECT"
        else:
            print(f"   ‚ùå –û—à–∏–±–æ–∫: {len(errors)} –∏–∑ {min_len}")
            critical = [e for e in errors if e['row'] in [1, 8, 11]]
            if critical:
                print(f"   –ö—Ä–∏—Ç–∏—á–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ (1,8,11): {len(critical)} –æ—à–∏–±–æ–∫")
                for err in critical:
                    print(f"     Row {err['row']}: '{err['result']}' vs '{err['reference']}'")
            status = "HAS_ERRORS"

        results.append({
            'file': f.relative_to(output_dir),
            'status': status,
            'errors': len(errors),
            'total': min_len
        })

        print()

    # –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞
    print("=" * 80)
    print("–ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê")
    print("=" * 80)

    perfect = [r for r in results if r['status'] == 'PERFECT']
    with_errors = [r for r in results if r['status'] == 'HAS_ERRORS']

    if perfect:
        print(f"\n‚úÖ –ò–î–ï–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ ({len(perfect)}):")
        for r in perfect:
            print(f"   ‚Ä¢ {r['file']}")

    if with_errors:
        print(f"\n‚ùå –†–ï–ó–£–õ–¨–¢–ê–¢–´ –° –û–®–ò–ë–ö–ê–ú–ò ({len(with_errors)}):")
        for r in sorted(with_errors, key=lambda x: x['errors']):
            print(f"   ‚Ä¢ {r['file']}: {r['errors']} –æ—à–∏–±–æ–∫ –∏–∑ {r['total']}")

if __name__ == "__main__":
    output_dir = Path("output")
    reference_file = Path("examples/gemini_thinking_2_prompts_v7/dnipromash_gemini_thinking_2_prompts_v7.json")

    merge_suffix_files(output_dir, reference_file)

